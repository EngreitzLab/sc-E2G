from snakemake.utils import min_version
min_version("7.0")

import pandas as pd
import os
import yaml


configfile: "config/config_training.yaml"
conda: "mamba"

model_config = pd.read_table(config["model_config"], na_values="").fillna("None").set_index("model", drop=False)
dataset_config = pd.read_table(config["dataset_config"], na_values="").set_index("biosample", drop=False)

def make_paths_absolute(obj, base_path):
	"""
	Use absolute paths to be compatible with github submodules
	Recursively go through the dictionary and convert relative paths to absolute paths.
	"""
	if isinstance(obj, dict):
		for key, value in obj.items():
			obj[key] = make_paths_absolute(value, base_path)
	elif isinstance(obj, str):
		# We assume all strings are paths. If converting the string
		# to an absolute path results in a valid file, then the str was a path
		new_file = os.path.join(base_path, obj)
		if os.path.exists(new_file):
			return new_file
	return obj

config = make_paths_absolute(config, os.getcwd())
# Need to manually make results_dir an absolute path since above may
# not work if results_dir folder isn't created
# If results_dir is already an absolute path, this is a no-op
config["results_dir"] = os.path.join(os.getcwd(), config["results_dir"])
RESULTS_DIR = config["results_dir"]
E2G_DIR_PATH = config["E2G_DIR_PATH"]

def get_e2g_config(config):
	e2g_config_file = os.path.join(E2G_DIR_PATH, "config/config_training.yaml")
	with open(e2g_config_file, 'r') as stream:
		e2g_config = yaml.safe_load(stream)
	e2g_config["E2G_DIR_PATH"] = E2G_DIR_PATH
	e2g_config["dataset_config"] = config["dataset_config"]
	e2g_config["model_config"] = config["model_config"]
	e2g_config["results_dir"] = config["results_dir"]
	e2g_config["run_feature_analysis"] = config["run_feature_analysis"]
	return e2g_config

module encode_e2g:
	snakefile:
		f"{E2G_DIR_PATH}/workflow/Snakefile_training"
	config: get_e2g_config(config)

use rule * from encode_e2g exclude add_external_features

rule add_external_features:
	input:
		predictions_extended = os.path.join(RESULTS_DIR, "{dataset}", "{model}", "ActivityOnly_features.tsv.gz"),
		arc_predictions = os.path.join(RESULTS_DIR, "{dataset}", "EnhancerPredictionsAllPutative_ARC.tsv.gz"),
		feature_table_file = lambda wildcards: model_config.loc[wildcards.model, "feature_table"]
	output:
		plus_external_features = os.path.join(RESULTS_DIR, "{dataset}", "{model}", "ActivityOnly_plus_external_features.tsv.gz")
	conda:
		"envs/sc_e2g.yml"
	script:
		"scripts/integrate_kendall.R"

rule kendall_correlation:
	input:
		kendall_candidate_e2g_pairs = lambda wildcards: dataset_config.loc[wildcards.dataset, 'candidate_pairs'],
		sc_atac_matix = lambda wildcards: dataset_config.loc[wildcards.dataset, 'ATAC_matrix'],
		sc_rna_matix = lambda wildcards: dataset_config.loc[wildcards.dataset, 'RNA_matrix']
	output:
		kendall_predictions = os.path.join(RESULTS_DIR, "{dataset}", "EnhancerPredictionsAllPutative_Kendall.tsv.gz") 
	conda:
		"envs/sc_e2g.yml"
	script:
		"scripts/compute_kendall.R"

rule arc_e2g:
	input:
		abc_predictions = os.path.join(RESULTS_DIR, "{dataset}", "Predictions", "EnhancerPredictionsAllPutative.tsv.gz"),
		kendall_predictions = os.path.join(RESULTS_DIR, "{dataset}", "EnhancerPredictionsAllPutative_Kendall.tsv.gz")
	output:
		arc_predictions = os.path.join(RESULTS_DIR, "{dataset}", "EnhancerPredictionsAllPutative_ARC.tsv.gz")
	conda:
		"envs/sc_e2g.yml"
	script:
		"scripts/compute_arc_e2g.R"

